{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5681f579-a30b-4fff-82b7-9e23e59e5328",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pyperch import Trainer\n",
    "from pyperch.config import TrainConfig, OptimizerConfig\n",
    "from pyperch.core.metrics import Accuracy\n",
    "from pyperch.utils import plot_losses, plot_accuracy\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 1. Reproducibility\n",
    "# -------------------------------------------------------------------\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 2. Make a simple binary classification dataset\n",
    "# -------------------------------------------------------------------\n",
    "X, y = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=12,\n",
    "    n_informative=10,\n",
    "    n_classes=2,\n",
    "    random_state=seed\n",
    ")\n",
    "X = X.astype(np.float32)\n",
    "y = y.astype(np.int64)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=seed\n",
    ")\n",
    "\n",
    "train_ds = TensorDataset(torch.tensor(X_train), torch.tensor(y_train))\n",
    "valid_ds = TensorDataset(torch.tensor(X_valid), torch.tensor(y_valid))\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "valid_loader = DataLoader(valid_ds, batch_size=128)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 3. Define a simple MLP classifier\n",
    "# -------------------------------------------------------------------\n",
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(12, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "model = SimpleClassifier()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 4. Configure RHC optimizer + metrics\n",
    "# -------------------------------------------------------------------\n",
    "opt_cfg = OptimizerConfig(\n",
    "    name=\"rhc\",\n",
    "    step_size=0.05,       # step size for hill climbing\n",
    ")\n",
    "\n",
    "cfg = TrainConfig(\n",
    "    device=\"cpu\",\n",
    "    seed=seed,\n",
    "    max_epochs=250,         # RHC is fast; can increase if needed\n",
    "    optimizer=\"rhc\",\n",
    "    optimizer_config=opt_cfg,\n",
    "    optimizer_mode=\"per_epoch\",   # RHC typically per-epoch\n",
    "    metrics={\n",
    "        \"train\": [Accuracy()],\n",
    "        \"valid\": [Accuracy()],\n",
    "    },\n",
    "    callbacks=[],          # HistoryCallback is auto-included\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 5. Train\n",
    "# -------------------------------------------------------------------\n",
    "trainer = Trainer(model, loss_fn, cfg)\n",
    "history = trainer.fit(train_loader, valid_loader)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 6. Plot loss curves\n",
    "# -------------------------------------------------------------------\n",
    "plot_losses(history)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 7. Plot accuracy curves\n",
    "# -------------------------------------------------------------------\n",
    "plot_accuracy(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6847ff-8cec-44ed-b7f4-68d23e848e77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pyperch import Trainer\n",
    "from pyperch.config import TrainConfig, OptimizerConfig\n",
    "from pyperch.core.metrics import MSE, R2\n",
    "from pyperch.utils import plot_losses\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 1. Reproducibility\n",
    "# -------------------------------------------------------------------\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 2. Regression dataset\n",
    "# -------------------------------------------------------------------\n",
    "X, y = make_regression(\n",
    "    n_samples=1000,\n",
    "    n_features=12,\n",
    "    n_informative=10,\n",
    "    noise=0.2,\n",
    "    random_state=seed,\n",
    ")\n",
    "\n",
    "X = X.astype(np.float32)\n",
    "y = y.reshape(-1, 1).astype(np.float32)  # 2D target\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=seed\n",
    ")\n",
    "\n",
    "train_ds = TensorDataset(torch.tensor(X_train), torch.tensor(y_train))\n",
    "valid_ds = TensorDataset(torch.tensor(X_valid), torch.tensor(y_valid))\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "valid_loader = DataLoader(valid_ds, batch_size=128)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 3. Simple MLP regressor\n",
    "# -------------------------------------------------------------------\n",
    "class SimpleRegressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(12, 32),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "model = SimpleRegressor()\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 4. RHC optimizer config + metrics (MSE + R²)\n",
    "# -------------------------------------------------------------------\n",
    "opt_cfg = OptimizerConfig(\n",
    "    name=\"rhc\",\n",
    "    step_size=0.5,\n",
    ")\n",
    "\n",
    "cfg = TrainConfig(\n",
    "    device=\"cpu\",\n",
    "    seed=seed,\n",
    "    max_epochs=500,              # tweak as needed\n",
    "    optimizer=\"rhc\",\n",
    "    optimizer_config=opt_cfg,\n",
    "    optimizer_mode=\"per_epoch\", # can try \"per_batch\" later\n",
    "    metrics={\n",
    "        \"train\": [MSE(), R2()],\n",
    "        \"valid\": [MSE(), R2()],\n",
    "    },\n",
    "    callbacks=[],\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 5. Train\n",
    "# -------------------------------------------------------------------\n",
    "trainer = Trainer(model, loss_fn, cfg)\n",
    "history = trainer.fit(train_loader, valid_loader)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 6. Plot loss learning curve (train + valid)\n",
    "# -------------------------------------------------------------------\n",
    "plot_losses(history)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 7. Plot R² learning curve (train + valid)\n",
    "# -------------------------------------------------------------------\n",
    "epochs = history[\"epoch\"]\n",
    "train_r2 = history[\"train_metrics\"].get(\"r2\", [])\n",
    "valid_r2 = history[\"valid_metrics\"].get(\"r2\", [])\n",
    "\n",
    "plt.figure()\n",
    "if train_r2:\n",
    "    plt.plot(epochs, train_r2, label=\"Train $R^2$\", color=\"cornflowerblue\")\n",
    "if valid_r2:\n",
    "    plt.plot(epochs, valid_r2, label=\"Validation $R^2$\", color=\"chartreuse\")\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"$R^2$\")\n",
    "plt.title(r\"Learning Curve – $R^2$ Score\")\n",
    "plt.grid(True)\n",
    "plt.legend(frameon=False)\n",
    "plt.tight_layout()\n",
    "\n",
    "print(\"Final train loss:\", history[\"train_loss\"][-1])\n",
    "print(\"Final valid loss:\", history[\"valid_loss\"][-1])\n",
    "if train_r2:\n",
    "    print(\"Final train R^2:\", train_r2[-1])\n",
    "if valid_r2:\n",
    "    print(\"Final valid R^2:\", valid_r2[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fbe78e-93ee-4d9f-a806-0be2f1de2c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from pyperch.config.schema import TrainConfig, OptimizerConfig\n",
    "from pyperch.core.trainer import Trainer\n",
    "from pyperch.core.metrics import Accuracy\n",
    "from pyperch.utils import plot_losses, plot_accuracy\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Dummy Classification Dataset\n",
    "# ------------------------------------------------------------\n",
    "np.random.seed(42)\n",
    "X = np.random.randn(500, 10).astype(np.float32)\n",
    "y = (np.sum(X[:, :3], axis=1) > 0).astype(np.int64)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Split dataset into train/valid\n",
    "# ------------------------------------------------------------\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_ds = TensorDataset(torch.tensor(X_train), torch.tensor(y_train))\n",
    "valid_ds = TensorDataset(torch.tensor(X_valid), torch.tensor(y_valid))\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(valid_ds, batch_size=32, shuffle=False)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Simple model for testing\n",
    "# ------------------------------------------------------------\n",
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(10, 16),   # <-- freeze this\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 2),    # <-- meta optimizer on this\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "model = SimpleClassifier()\n",
    "\n",
    "# Capture original weights for freeze verification\n",
    "original_w0 = model.net[0].weight.detach().clone()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# TrainConfig for freeze+meta\n",
    "# ------------------------------------------------------------\n",
    "cfg = TrainConfig(\n",
    "    device=\"cpu\",\n",
    "    max_epochs=10,\n",
    "    seed=42,\n",
    "    optimizer=\"rhc\",\n",
    "    optimizer_mode=\"per_batch\",\n",
    "    optimizer_config=OptimizerConfig(step_size=0.5),\n",
    "\n",
    "    # ADD VALID ACCURACY\n",
    "    metrics={\n",
    "        \"train\": [Accuracy()],\n",
    "        \"valid\": [Accuracy()],\n",
    "    },\n",
    "\n",
    "    layer_modes={\n",
    "        \"net.0.weight\": \"freeze\",\n",
    "        \"net.0.bias\": \"freeze\",\n",
    "        \"net.2.weight\": \"meta\",\n",
    "        \"net.2.bias\": \"meta\",\n",
    "    }\n",
    ")\n",
    "\n",
    "trainer = Trainer(model, nn.CrossEntropyLoss(), cfg)\n",
    "\n",
    "# IMPORTANT FIX → include valid_loader here:\n",
    "history = trainer.fit(train_loader, valid_loader)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Freeze Verification\n",
    "# ------------------------------------------------------------\n",
    "print(\"Frozen layer unchanged:\",\n",
    "      torch.allclose(original_w0, model.net[0].weight.detach()))\n",
    "\n",
    "plot_losses(history)\n",
    "plot_accuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4debce3-1301-4d2f-8580-c5b2fdbcde1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hybrid test: \n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Hybrid Layer Modes: grad + meta\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "model = SimpleClassifier()\n",
    "\n",
    "cfg = TrainConfig(\n",
    "    device=\"cpu\",\n",
    "    max_epochs=15,\n",
    "    seed=42,\n",
    "\n",
    "    optimizer=\"rhc\",  # meta optimizer for layer 2\n",
    "    optimizer_mode=\"per_batch\",\n",
    "    optimizer_config=OptimizerConfig(step_size=0.5),\n",
    "\n",
    "    # ADD VALID ACCURACY\n",
    "    metrics={\n",
    "        \"train\": [Accuracy()],\n",
    "        \"valid\": [Accuracy()],\n",
    "    },\n",
    "\n",
    "    # Hybrid: Layer 0 = Adam, Layer 2 = RHC\n",
    "    layer_modes={\n",
    "        \"net.0.weight\": \"grad\",\n",
    "        \"net.0.bias\": \"grad\",\n",
    "        \"net.2.weight\": \"meta\",\n",
    "        \"net.2.bias\": \"meta\",\n",
    "    }\n",
    ")\n",
    "\n",
    "trainer = Trainer(model, nn.CrossEntropyLoss(), cfg)\n",
    "\n",
    "# IMPORTANT FIX → include valid_loader here:\n",
    "history = trainer.fit(train_loader, valid_loader)\n",
    "\n",
    "plot_losses(history)\n",
    "plot_accuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225adea6-f48a-4b38-8b70-c3657fb413cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#freeze + hybrid\n",
    "# ------------------------------------------------------------\n",
    "# Freeze first layer\n",
    "# Train middle with Adam\n",
    "# Train output with RHC\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "model = SimpleClassifier()\n",
    "\n",
    "cfg = TrainConfig(\n",
    "    device=\"cpu\",\n",
    "    max_epochs=15,\n",
    "    seed=42,\n",
    "\n",
    "    optimizer=\"rhc\",                 # Meta optimizer for output layer\n",
    "    optimizer_mode=\"per_batch\",\n",
    "    optimizer_config=OptimizerConfig(step_size=0.5),\n",
    "\n",
    "    # ADD VALID ACCURACY\n",
    "    metrics={\n",
    "        \"train\": [Accuracy()],\n",
    "        \"valid\": [Accuracy()],\n",
    "    },\n",
    "\n",
    "    layer_modes={\n",
    "        \"net.0.weight\": \"freeze\",    # First layer frozen\n",
    "        \"net.0.bias\": \"freeze\",\n",
    "\n",
    "        # NOTE: Middle layer defaults to \"meta\" unless explicitly set.\n",
    "        # If you want middle layer to be Adam, set \"grad\" here.\n",
    "\n",
    "        \"net.2.weight\": \"meta\",      # Output layer trained by RHC\n",
    "        \"net.2.bias\":  \"meta\",\n",
    "    }\n",
    ")\n",
    "\n",
    "trainer = Trainer(model, nn.CrossEntropyLoss(), cfg)\n",
    "\n",
    "# IMPORTANT: include valid_loader so validation curves appear\n",
    "history = trainer.fit(train_loader, valid_loader)\n",
    "\n",
    "plot_losses(history)\n",
    "plot_accuracy(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83d2ae6-9f5a-4242-b3b8-25facf05f8b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyperch",
   "language": "python",
   "name": "pyperch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
